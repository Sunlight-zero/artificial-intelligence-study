{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrozenLake:\n",
    "    def __init__(self, nrow: int, ncol: int, holes: list[int]):\n",
    "        self.nrow = nrow\n",
    "        self.ncol = ncol\n",
    "        self.n_states = nrow * ncol + 1\n",
    "        # 0 for a empty slot, 1 for the terminal, -1 for a hole, 2 for an absorption\n",
    "        self.states = np.zeros(self.n_states, dtype=np.int32)\n",
    "        self.states[holes] = -1\n",
    "        self.states[self.n_states - 2] = 1\n",
    "        self.states[self.n_states - 1] = 2\n",
    "        self.absorption = self.n_states - 1\n",
    "        # for action: 0 for up, 1 for down, 2 for left, 3 for right.\n",
    "        self.n_actions = 4\n",
    "        # Initialize transition matrix and reward\n",
    "        self.transition = np.zeros(\n",
    "            (self.n_states, self.n_actions, self.n_states), dtype=np.float64\n",
    "        )\n",
    "        self.reward = np.zeros(\n",
    "            (self.n_states, self.n_actions), dtype=np.float64\n",
    "        )\n",
    "        for action in range(self.n_actions):\n",
    "            self.transition[self.absorption, action, self.absorption] = 1\n",
    "        \n",
    "        for x in range(nrow):\n",
    "            for y in range(ncol):\n",
    "                state = x * ncol + y\n",
    "                if self.states[state] != 0:\n",
    "                    if self.states[state] == -1:\n",
    "                        reward = -100\n",
    "                    elif self.states[state] == 1:\n",
    "                        reward = 1000\n",
    "                    # Terminate\n",
    "                    for action in range(self.n_actions):\n",
    "                        self.transition[state, action, self.absorption] = 1\n",
    "                        self.reward[state, action] = reward\n",
    "                    continue\n",
    "                can_up = can_down = can_left = can_right = True\n",
    "                if x == 0:\n",
    "                    can_up = False\n",
    "                if x == nrow - 1:\n",
    "                    can_down = False\n",
    "                if y == 0:\n",
    "                    can_left = False\n",
    "                if y == ncol - 1:\n",
    "                    can_right = False\n",
    "                for action in range(self.n_actions):\n",
    "                    if can_up and action != 1:\n",
    "                        next_state = (x - 1) * ncol + y\n",
    "                        self.transition[state, action, next_state] = 1\n",
    "                    if can_down and action != 0:\n",
    "                        next_state = (x + 1) * ncol + y\n",
    "                        self.transition[state, action, next_state] = 1\n",
    "                    if can_left and action != 3:\n",
    "                        next_state = x * ncol + y - 1\n",
    "                        self.transition[state, action, next_state] = 1\n",
    "                    if can_right and action != 2:\n",
    "                        next_state = x * ncol + y + 1\n",
    "                        self.transition[state, action, next_state] = 1\n",
    "                    if (s := np.sum(self.transition[state, action])) != 0:\n",
    "                        self.transition[state, action] *= 1 / s\n",
    "    \n",
    "    def step(self, state: int, action: int) -> tuple[int, float, bool]:\n",
    "        \"\"\"\n",
    "        return (state, reward, is_end)\n",
    "        \"\"\"\n",
    "        reward = self.reward[state, action]\n",
    "        if self.states[state] != 0:\n",
    "            return (-1, reward, True)\n",
    "        distribution = self.transition[state, action]\n",
    "        next_state = random.choices(np.arange(self.n_states), distribution)[0]\n",
    "        return (next_state, reward, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_states = 17\n",
    "n_actions = 4\n",
    "epsilon = 0.2\n",
    "gamma = 0.95\n",
    "alpha = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = FrozenLake(4, 4, [5, 7, 11, 12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def espilon_greedy(state: int, epsilon: int, q_table: np.ndarray):\n",
    "    if random.random() < epsilon:\n",
    "        action = random.choice(list(range(n_actions)))\n",
    "    else:\n",
    "        action = np.argmax(q_table[state])\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25491036, 0.77544495, 0.24071575, 0.0845058 ],\n",
       "       [0.78742329, 0.99947557, 0.81749056, 0.25958351],\n",
       "       [0.66585525, 0.82939271, 0.41254837, 0.14451091],\n",
       "       [0.06202279, 0.30303769, 0.4470478 , 0.42327232],\n",
       "       [0.78664478, 0.32911941, 0.37687248, 0.1520113 ],\n",
       "       [0.0331673 , 0.29848245, 0.74189371, 0.11847933],\n",
       "       [0.64723036, 0.25703982, 0.24822253, 0.77120818],\n",
       "       [0.52113806, 0.8753327 , 0.63794396, 0.85828247],\n",
       "       [0.06310311, 0.40367328, 0.15411999, 0.64543417],\n",
       "       [0.96704758, 0.98239206, 0.81370209, 0.04766594],\n",
       "       [0.62361502, 0.32431166, 0.04254495, 0.49339122],\n",
       "       [0.35481324, 0.84851958, 0.67491983, 0.15771248],\n",
       "       [0.27223153, 0.8929767 , 0.88813526, 0.26147043],\n",
       "       [0.36483432, 0.6726103 , 0.11192658, 0.79139059],\n",
       "       [0.25512323, 0.00913324, 0.47924283, 0.84423774],\n",
       "       [0.39702672, 0.1508288 , 0.9080625 , 0.8722814 ],\n",
       "       [0.31122746, 0.15908299, 0.04615175, 0.09967401]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table = np.random.random((n_states, n_actions))\n",
    "q_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 13031.14it/s]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10000\n",
    "max_steps = 10000\n",
    "\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    state = 0\n",
    "    action = espilon_greedy(state, epsilon, q_table)\n",
    "    is_end = False\n",
    "    while not is_end:\n",
    "        next_state, reward, is_end = env.step(state, action)\n",
    "        next_action = espilon_greedy(next_state, epsilon, q_table)\n",
    "        q_table[state, action] += \\\n",
    "            alpha * (reward + gamma * q_table[next_state, next_action] - q_table[state, action])\n",
    "        state, action = next_state, next_action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['<', '^', '<', '^'],\n",
       "       ['<', '>', '>', '<'],\n",
       "       ['^', 'v', '<', '<'],\n",
       "       ['<', '>', 'v', '<']], dtype='<U1')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = np.argmax(q_table, axis=1)\n",
    "np.array(list(map(lambda x: \"^v<>\"[x], policy))[:-1]).reshape(4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.00553229e+01,  2.38286226e+01,  6.75698429e+01,\n",
       "         2.43956466e+01],\n",
       "       [ 3.65043072e+01, -3.21435440e+01, -5.10137734e+01,\n",
       "        -4.16584977e+01],\n",
       "       [ 5.15217411e+00,  8.71519675e+00,  3.60204409e+01,\n",
       "         9.80962294e+00],\n",
       "       [ 1.73179613e+01, -4.91583226e+01, -3.42472315e+01,\n",
       "        -4.46582798e+01],\n",
       "       [-3.78497279e+01, -1.75656474e+00,  7.97111902e+01,\n",
       "        -3.64976142e+00],\n",
       "       [-9.97352680e+01, -9.97537708e+01, -9.97371259e+01,\n",
       "        -9.97057157e+01],\n",
       "       [-4.00420187e+01, -1.49549127e+01,  1.52948613e+01,\n",
       "         2.98644523e+01],\n",
       "       [-9.54896687e+01, -9.58886755e+01, -9.50349953e+01,\n",
       "        -9.58747769e+01],\n",
       "       [ 1.15808105e+02,  2.51102180e+01, -3.81810183e+01,\n",
       "         3.86749641e+01],\n",
       "       [ 3.45680774e+01,  2.11287107e+02,  6.48619070e+01,\n",
       "         1.35707072e+02],\n",
       "       [ 3.74161243e+01,  1.14592567e+02,  2.43852065e+02,\n",
       "         8.68149013e+01],\n",
       "       [-9.08493396e+01, -9.17020965e+01, -9.08325442e+01,\n",
       "        -9.08779181e+01],\n",
       "       [-9.86334913e+01, -9.86415526e+01, -9.83991853e+01,\n",
       "        -9.85273576e+01],\n",
       "       [ 2.57963227e+02,  1.93988495e+02,  3.09247164e+01,\n",
       "         3.18860042e+02],\n",
       "       [ 3.36045770e+02,  4.91439587e+02,  7.35791962e+01,\n",
       "         4.10440316e+02],\n",
       "       [ 5.69862605e+02,  8.33475846e+02,  1.00027961e+03,\n",
       "         6.51797843e+02],\n",
       "       [ 3.11227461e-01,  1.59082988e-01,  4.61517501e-02,\n",
       "         9.96740055e-02]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
